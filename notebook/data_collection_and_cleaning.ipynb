{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering and Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is collected from google images and manually from youtube, twitter, instagram. After collecting images for both classes `Swiggy` and `Other`. the images are passed to FasterRCNN network to crop person images. The person images are manually cross verified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required library\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib import request\n",
    "from io import BytesIO\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from imutils import paths\n",
    "import imutils\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "In this section we collect data from google images web page. As Google Images can provide a variety of different images that can and cant be revelent, manual cross verification is need to be done ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was collected from various sources, those are,\n",
    "\n",
    "1. Goggle Images \n",
    "2. Twitter (Videos with #Swiggydelivary, #Zomatodelivary, etc. and then manual crop in certain interval)\n",
    "3. Instagram (Images and Videos with #Swiggydelivary, #Zomatodelivary, etc.)\n",
    "4. Facebook (Images with #Swiggydelivary, #Zomatodelivary, etc.)\n",
    "\n",
    "Images of different food delivary person, like Zomato, Dunzo was collected to train as negative samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download from Google Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request webpage \n",
    "header = {'User-Agent':\"Mozilla/5.0\"}\n",
    "url=\"https://www.google.com/search?q=zomato+delivery+boy+shirt&client=firefox-b-d&sxsrf=ALeKk02vh7T2tqrnRYi907Aa1igdlxg78Q:1597761930173&source=lnms&tbm=isch&sa=X&ved=2ahUKEwiGi6KC_6TrAhX8yDgGHUenBb0Q_AUoAXoECA4QAw&biw=1366&bih=654\"\n",
    "html = BeautifulSoup(request.urlopen(request.Request(url, headers=header)),'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read and save all the images images\n",
    "for ii, img in enumerate(html.find_all(\"img\")):\n",
    "    try:\n",
    "        Image.open(BytesIO(request.urlopen(img.attrs['data-src']).read())).save(f\"{ii}.jpg\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")\n",
    "        continue\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping above code together\n",
    "def download_images(path:str, url:str):\n",
    "    \"\"\"\n",
    "    Download Images from google image url and save to provided path\n",
    "    Input: path(str) :: Path where to save images\n",
    "           url(str) :: Url(Google Images)\n",
    "    Output: Int :: Number of saved Images\n",
    "    \"\"\"\n",
    "    header = {'User-Agent':\"Mozilla/5.0\"} #header\n",
    "    html = BeautifulSoup(request.urlopen(request.Request(url, headers=header)),'html.parser') #request html page\n",
    "    num_of_images = 0 #varaible to count umber of sucessful images\n",
    "    \n",
    "    for ii, img in enumerate(html.find_all(\"img\",{\"class\":\"rg_i Q4LuWd\"})):# find all image tages\n",
    "        try:\n",
    "            #save image and increment counter\n",
    "            Image.open(BytesIO(urllib2.request.urlopen(img.attrs['data-src']).read())).save(f\"{path}/{ii}.jpg\")\n",
    "            num_of_images +=1\n",
    "        except Exception as e:\n",
    "            # image link not present\n",
    "            print(e.desc)\n",
    "            continue\n",
    "    # return no of saved images\n",
    "    return num_of_images\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_swiggy = \n",
    "url_zomato = \n",
    "url_dunzo =\n",
    "url_foodpanda = \n",
    "url_monkey = \n",
    "url_cat =\n",
    "url_dog = \n",
    "url_person = \n",
    "\n",
    "print(f\"{download_images(\"../data/multilabel-classification/images/swiggy\", url_swiggy)}Number of Swiggy images downloaded\")\n",
    "print(f\"{download_images(\"../data/multilabel-classification/images/others\", url_zomato)}Number of zomato images downloaded\")\n",
    "print(f\"{download_images(\"../data/multilabel-classification/images/others\", url_dunzo)}Number of dunzo images downloaded\")\n",
    "print(f\"{download_images(\"../data/multilabel-classification/images/others\", url_foodpanda)}Number of foodpanda images downloaded\")\n",
    "print(f\"{download_images(\"../data/multilabel-classification/images/non-human/\", url_monkey)}Number of monkey images downloaded\")\n",
    "print(f\"{download_images(\"../data/multilabel-classification/images/non-human/\", url_cat)}Number of cat images downloaded\")\n",
    "print(f\"{download_images(\"../data/multilabel-classification/images/non-human/\", url_dog)}Number of dog images downloaded\")\n",
    "print(f\"{download_images(\"../data/multilabel-classification/images/others\", url_person)}Number of person images downloaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images of swiggy, zomato, dunzo, foodpanda, animals(monkey, cat, dog) are extracted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person Crop\n",
    "Assuming a test image will contains only single person on a frame/image. It will boost accuracy if training sample also contains such images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and preprocess image for model\n",
    "\n",
    "def load_image(img_path:str):\n",
    "    \"\"\"\n",
    "    Load and tranfrom image that can be send to pytorch trained model\n",
    "    Input : img_path(str): path to image file\n",
    "    Output : Torch.tensor  \n",
    "    \n",
    "    \"\"\"\n",
    "    image = Image.open(img_path).convert('RGB') #load image and change to RGB chanel\n",
    "    in_transform = transforms.Compose([\n",
    "                        transforms.ToTensor()]) # cvt image to tensor \n",
    "    # discard the transparent, alpha channel (that's the :3) and add the batch dimension\n",
    "    image = in_transform(image)[:3,:,:].unsqueeze(0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pretrained Faster RRCNN model\n",
    "fasterrcnn = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "#check if GPU is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "#tranfer to gpu if available\n",
    "if use_cuda:\n",
    "    fasterrcnn = mfasterrcnnodel.cuda()\n",
    "\n",
    "# set model to evaluation\n",
    "fasterrcnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def croped_person(path_to_image:str):\n",
    "    \"\"\"\n",
    "    Extract and crop persons from fiven image path. Returns list of croped person images\\\n",
    "    Input : path_to_image(str):: oath to image from which want to extract persin\n",
    "    Output : List :: List of croped person images\n",
    "    \"\"\"\n",
    "    #load image\n",
    "    img = load_image(path_to_image)\n",
    "    #transfer image to gpu if available\n",
    "    if use_cuda:\n",
    "        img = img.cuda()\n",
    "    # get bounding box \n",
    "    pred = fasterrcnn(img)\n",
    "    \n",
    "    #extract person bounding box with score > 0.9\n",
    "    person_ids = [ind for ind, val in (filter(lambda x: x[1] == 1, enumerate(pred[0]['labels'])))]\n",
    "    person_ids = [ind for ind, val in (filter(lambda x: x[1] > 0.9, enumerate(pred[0]['scores'][person_ids])))]\n",
    "    \n",
    "    #extracted boxes\n",
    "    boxes = pred[0]['boxes'][person_ids].cpu().detach().numpy()\n",
    "\n",
    "    #apply non max supression\n",
    "    boxes = non_max_suppression(boxes, probs=None, overlapThresh=0.80)\n",
    "    \n",
    "    #read image to crop\n",
    "    img = cv2.imread(path_to_image)\n",
    "    cropped = [] #list of cropeed person images\n",
    "    \n",
    "    for rect in boxes:\n",
    "        cropped.append(img[rect[1]:rect[3],rect[0]:rect[2]])\n",
    "        \n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract person from Swiggy and other dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swiggy_persons = []\n",
    "path = \"../data/multilabel-classification/images/swiggy/\"\n",
    "for img in os.listdir(path):\n",
    "    path_img = path+img\n",
    "    swiggy_persons.append(croped_person(path_img))\n",
    "    \n",
    "# save extracted person    \n",
    "np.save('../data/swiggy.npy',np.array(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_persons = []\n",
    "path = \"../data/multilabel-classification/images/other/\"\n",
    "for img in os.listdir(path):\n",
    "    path_img = path+img\n",
    "    other_persons.append(croped_person(path_img))\n",
    "\n",
    "# save extracted person \n",
    "np.save('other.npy',np.array(ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint \n",
    "Can continue from here if notebook restart or for a new session (after import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load extracted list of person for swiggy and other\n",
    "swiggy = np.load('../data/swiggy.npy', allow_pickle=True)\n",
    "other = np.load('../data/other.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save image \n",
    "def write_img(path:str, matrix:list):\n",
    "    \"\"\"\n",
    "    Saves images from list of images\n",
    "    Input : path(str) :: Path in whiuch have to save images\n",
    "            matrix(list/array) :: matrix conating list of person for each images\n",
    "    Output : None\n",
    "    \"\"\"\n",
    "    i=0 #file name\n",
    "    for image in matrix:\n",
    "        #for each image\n",
    "        for person in image:\n",
    "            # for each person detectd in image\n",
    "            cv2.imwrite(f\"{path}/{i}.jpg\",person) #write image\n",
    "            i+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cropped person image\n",
    "write_img('../data/classification/swiggy', swiggy)\n",
    "write_img('../data/classification/other', other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracted Person from each images and manually removed/cleaned false images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logo\n",
    "As Swiggy logo can also be important feature it will be a important turning point if we can identify Swiggy logo in image. I have hand  cropped and labelled Swiggy logo in every image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating CSV file for images\n",
    "For training a multi label classifier, it will be convinent to have a csv file with image path and lables. For labels we can suffice only on two, one for `Human` and other for `Swiggy`. The lower value for labels can denote `No-Human` and `Other` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data dir\n",
    "data_path = '../data/multilabel-classification/images/'\n",
    "classes = ['human/swiggy', 'human/other', 'non-human/swiggy', 'non-human/other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 5 Items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('../data/multilabel-classification/images/human/swiggy/163.jpg', [1, 1]),\n",
       " ('../data/multilabel-classification/images/human/swiggy/65.jpg', [1, 1]),\n",
       " ('../data/multilabel-classification/images/human/swiggy/150.jpg', [1, 1]),\n",
       " ('../data/multilabel-classification/images/human/swiggy/221.jpg', [1, 1]),\n",
       " ('../data/multilabel-classification/images/human/swiggy/158.jpg', [1, 1])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dataframe to store image path and one hot encoded labels\n",
    "list_of_images = []\n",
    "list_of_tags = []\n",
    "\n",
    "mapping = {'human':1,\n",
    "          'non-human':0,\n",
    "          'swiggy':1,\n",
    "          'other':0}\n",
    "\n",
    "for cls in classes:\n",
    "    #for each class\n",
    "    for img in os.listdir(f\"{data_path}{cls}\"):\n",
    "        # for each image in a class\n",
    "        img_path = f\"{data_path}{cls}/{img}\"\n",
    "        \n",
    "        # labeling image as [Human,Swiggy] \n",
    "        labels = list(map(lambda x : mapping[x],cls.split('/')))\n",
    "        \n",
    "        list_of_images.append(img_path)\n",
    "        list_of_tags.append(labels)\n",
    "\n",
    "print(\"Sample 5 Items\")\n",
    "list(zip(list_of_images[:5], list_of_tags[:5]))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>../data/multilabel-classification/images/human...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>../data/multilabel-classification/images/human...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>../data/multilabel-classification/images/human...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>../data/multilabel-classification/images/human...</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>../data/multilabel-classification/images/non-h...</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>../data/multilabel-classification/images/human...</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>../data/multilabel-classification/images/human...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>../data/multilabel-classification/images/human...</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>../data/multilabel-classification/images/non-h...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>../data/multilabel-classification/images/non-h...</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path  labels\n",
       "299  ../data/multilabel-classification/images/human...  [1, 0]\n",
       "365  ../data/multilabel-classification/images/human...  [1, 0]\n",
       "254  ../data/multilabel-classification/images/human...  [1, 0]\n",
       "46   ../data/multilabel-classification/images/human...  [1, 1]\n",
       "761  ../data/multilabel-classification/images/non-h...  [0, 0]\n",
       "168  ../data/multilabel-classification/images/human...  [1, 1]\n",
       "308  ../data/multilabel-classification/images/human...  [1, 0]\n",
       "27   ../data/multilabel-classification/images/human...  [1, 1]\n",
       "559  ../data/multilabel-classification/images/non-h...  [0, 1]\n",
       "800  ../data/multilabel-classification/images/non-h...  [0, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load into DataFrame\n",
    "\n",
    "df = pd.DataFrame([list_of_images, list_of_tags]).T\n",
    "df.columns = ['path', 'labels']\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>labels</th>\n",
       "      <th>human</th>\n",
       "      <th>swiggy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>../data/multilabel-classification/images/non-h...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>../data/multilabel-classification/images/human...</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>../data/multilabel-classification/images/human...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>../data/multilabel-classification/images/human...</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>../data/multilabel-classification/images/non-h...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>../data/multilabel-classification/images/non-h...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>../data/multilabel-classification/images/human...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>../data/multilabel-classification/images/human...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>../data/multilabel-classification/images/human...</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>../data/multilabel-classification/images/human...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path  labels  human  swiggy\n",
       "768  ../data/multilabel-classification/images/non-h...  [0, 0]      0       0\n",
       "351  ../data/multilabel-classification/images/human...  [1, 0]      1       0\n",
       "189  ../data/multilabel-classification/images/human...  [1, 1]      1       1\n",
       "429  ../data/multilabel-classification/images/human...  [1, 0]      1       0\n",
       "646  ../data/multilabel-classification/images/non-h...  [0, 0]      0       0\n",
       "450  ../data/multilabel-classification/images/non-h...  [0, 1]      0       1\n",
       "65   ../data/multilabel-classification/images/human...  [1, 1]      1       1\n",
       "210  ../data/multilabel-classification/images/human...  [1, 1]      1       1\n",
       "250  ../data/multilabel-classification/images/human...  [1, 0]      1       0\n",
       "130  ../data/multilabel-classification/images/human...  [1, 1]      1       1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding \n",
    "\n",
    "df['human'] = df['labels'].apply(lambda x : x[0])\n",
    "df['swiggy'] = df['labels'].apply(lambda x : x[1])\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>labels</th>\n",
       "      <th>human</th>\n",
       "      <th>swiggy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/multilabel-classification/images/human...</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/multilabel-classification/images/human...</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/multilabel-classification/images/non-h...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/multilabel-classification/images/non-h...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/multilabel-classification/images/human...</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  labels  human  swiggy\n",
       "0  ../data/multilabel-classification/images/human...  [1, 0]      1       0\n",
       "1  ../data/multilabel-classification/images/human...  [1, 0]      1       0\n",
       "2  ../data/multilabel-classification/images/non-h...  [0, 1]      0       1\n",
       "3  ../data/multilabel-classification/images/non-h...  [0, 0]      0       0\n",
       "4  ../data/multilabel-classification/images/human...  [1, 0]      1       0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle datframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save labels file as csv\n",
    "df.to_csv('../data/multilabel-classification/labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Split lables into train, test, val\n",
    "\n",
    "train_size = 0.7\n",
    "\n",
    "train, other = train_test_split(df, train_size=train_size)\n",
    "val, test = train_test_split(other, test_size=0.5)\n",
    "\n",
    "train.to_csv('../data/multilabel-classification/train.csv', index=False)\n",
    "val.to_csv('../data/multilabel-classification/val.csv', index=False)\n",
    "test.to_csv('../data/multilabel-classification/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done !!\n",
    "In this Notebook we have \n",
    "* Collected data\n",
    "* Extracted Person from Images\n",
    "* Extracted logo from Images\n",
    "* Created labels csv for multi label classification\n",
    "* Split Dataset into train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
